{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ludwig-test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gwohlgen/colab/blob/master/ludwig_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtrkgY5MNdPC",
        "colab_type": "text"
      },
      "source": [
        "# ludwig test on spam / ham dataset\n",
        "Based on: \n",
        "l"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7Sq_dFpNWZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!wget https://aic.ai.wu.ac.at/~wohlg/spam1.csv\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJcWw_XlNwVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install ludwig\n",
        "!python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsEmBhH-QOZs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7857
        },
        "outputId": "fe4217b1-c74b-417c-dee8-d5dc16fa72e2"
      },
      "source": [
        "!ludwig train --data_csv spam1.csv --model_definition \"{input_features: [{name: text, type: text}], output_features: [{name: label, type: category}]}\"\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            " _         _        _      \n",
            "| |_  _ __| |_ __ _(_)__ _ \n",
            "| | || / _` \\ V  V / / _` |\n",
            "|_|\\_,_\\__,_|\\_/\\_/|_\\__, |\n",
            "                     |___/ \n",
            "ludwig v0.1.2 - Train\n",
            "\n",
            "Experiment name: experiment\n",
            "Model name: run\n",
            "Output path: results/experiment_run_0\n",
            "\n",
            "\n",
            "ludwig_version: '0.1.2'\n",
            "command: ('/usr/local/bin/ludwig train --data_csv spam1.csv --model_definition '\n",
            " '{input_features: [{name: text, type: text}], output_features: [{name: label, '\n",
            " 'type: category}]}')\n",
            "random_seed: 42\n",
            "input_data: 'spam1.csv'\n",
            "model_definition: {   'combiner': {'type': 'concat'},\n",
            "    'input_features': [   {   'encoder': 'parallel_cnn',\n",
            "                              'level': 'word',\n",
            "                              'name': 'text',\n",
            "                              'tied_weights': None,\n",
            "                              'type': 'text'}],\n",
            "    'output_features': [   {   'dependencies': [],\n",
            "                               'loss': {   'class_similarities_temperature': 0,\n",
            "                                           'class_weights': 1,\n",
            "                                           'confidence_penalty': 0,\n",
            "                                           'distortion': 1,\n",
            "                                           'labels_smoothing': 0,\n",
            "                                           'negative_samples': 0,\n",
            "                                           'robust_lambda': 0,\n",
            "                                           'sampler': None,\n",
            "                                           'type': 'softmax_cross_entropy',\n",
            "                                           'unique': False,\n",
            "                                           'weight': 1},\n",
            "                               'name': 'label',\n",
            "                               'reduce_dependencies': 'sum',\n",
            "                               'reduce_input': 'sum',\n",
            "                               'top_k': 3,\n",
            "                               'type': 'category'}],\n",
            "    'preprocessing': {   'bag': {   'fill_value': '',\n",
            "                                    'format': 'space',\n",
            "                                    'lowercase': False,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': 10000},\n",
            "                         'binary': {   'fill_value': 0,\n",
            "                                       'missing_value_strategy': 'fill_with_const'},\n",
            "                         'category': {   'fill_value': '<UNK>',\n",
            "                                         'lowercase': False,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 10000},\n",
            "                         'force_split': False,\n",
            "                         'image': {   'in_memory': True,\n",
            "                                      'missing_value_strategy': 'backfill',\n",
            "                                      'resize_method': 'crop_or_pad'},\n",
            "                         'numerical': {   'fill_value': 0,\n",
            "                                          'missing_value_strategy': 'fill_with_const'},\n",
            "                         'sequence': {   'fill_value': '',\n",
            "                                         'format': 'space',\n",
            "                                         'lowercase': False,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 20000,\n",
            "                                         'padding': 'right',\n",
            "                                         'padding_symbol': '<PAD>',\n",
            "                                         'sequence_length_limit': 256,\n",
            "                                         'unknown_symbol': '<UNK>'},\n",
            "                         'set': {   'fill_value': '',\n",
            "                                    'format': 'space',\n",
            "                                    'lowercase': False,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': 10000},\n",
            "                         'split_probabilities': (0.7, 0.1, 0.2),\n",
            "                         'stratify': None,\n",
            "                         'text': {   'char_format': 'characters',\n",
            "                                     'char_most_common': 70,\n",
            "                                     'char_sequence_length_limit': 1024,\n",
            "                                     'fill_value': '',\n",
            "                                     'lowercase': True,\n",
            "                                     'missing_value_strategy': 'fill_with_const',\n",
            "                                     'padding': 'right',\n",
            "                                     'padding_symbol': '<PAD>',\n",
            "                                     'unknown_symbol': '<UNK>',\n",
            "                                     'word_format': 'space_punct',\n",
            "                                     'word_most_common': 20000,\n",
            "                                     'word_sequence_length_limit': 256},\n",
            "                         'timeseries': {   'fill_value': '',\n",
            "                                           'format': 'space',\n",
            "                                           'missing_value_strategy': 'fill_with_const',\n",
            "                                           'padding': 'right',\n",
            "                                           'padding_value': 0,\n",
            "                                           'timeseries_length_limit': 256}},\n",
            "    'training': {   'batch_size': 128,\n",
            "                    'bucketing_field': None,\n",
            "                    'decay': False,\n",
            "                    'decay_rate': 0.96,\n",
            "                    'decay_steps': 10000,\n",
            "                    'dropout_rate': 0.0,\n",
            "                    'early_stop': 5,\n",
            "                    'epochs': 100,\n",
            "                    'eval_batch_size': 0,\n",
            "                    'gradient_clipping': None,\n",
            "                    'increase_batch_size_on_plateau': 0,\n",
            "                    'increase_batch_size_on_plateau_max': 512,\n",
            "                    'increase_batch_size_on_plateau_patience': 5,\n",
            "                    'increase_batch_size_on_plateau_rate': 2,\n",
            "                    'learning_rate': 0.001,\n",
            "                    'learning_rate_warmup_epochs': 5,\n",
            "                    'optimizer': {   'beta1': 0.9,\n",
            "                                     'beta2': 0.999,\n",
            "                                     'epsilon': 1e-08,\n",
            "                                     'type': 'adam'},\n",
            "                    'reduce_learning_rate_on_plateau': 0,\n",
            "                    'reduce_learning_rate_on_plateau_patience': 5,\n",
            "                    'reduce_learning_rate_on_plateau_rate': 0.5,\n",
            "                    'regularization_lambda': 0,\n",
            "                    'regularizer': 'l2',\n",
            "                    'staircase': False,\n",
            "                    'validation_field': 'combined',\n",
            "                    'validation_measure': 'loss'}}\n",
            "\n",
            "\n",
            "Using full raw csv, no hdf5 and json file with the same name have been found\n",
            "Building dataset (it may take a while)\n",
            "Writing dataset\n",
            "Writing train set metadata with vocabulary\n",
            "Training set: 3939\n",
            "Validation set: 525\n",
            "Test set: 1108\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "\n",
            "╒══════════╕\n",
            "│ TRAINING │\n",
            "╘══════════╛\n",
            "\n",
            "2019-05-21 22:27:38.369285: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-05-21 22:27:38.369766: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2304ec0 executing computations on platform Host. Devices:\n",
            "2019-05-21 22:27:38.369798: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-05-21 22:27:38.550015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-05-21 22:27:38.550607: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2304aa0 executing computations on platform CUDA. Devices:\n",
            "2019-05-21 22:27:38.550637: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-05-21 22:27:38.550960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-05-21 22:27:38.550981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-05-21 22:27:39.999449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-05-21 22:27:39.999511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-05-21 22:27:39.999524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-05-21 22:27:39.999790: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-05-21 22:27:39.999867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "\n",
            "Epoch   1\n",
            "Training:   0% 0/31 [00:00<?, ?it/s]2019-05-21 22:27:40.671812: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "Training: 100% 31/31 [00:05<00:00,  9.56it/s]\n",
            "Evaluation train: 100% 31/31 [00:00<00:00, 61.53it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 61.77it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 44.77it/s]\n",
            "Took 6.6325s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0538 │     0.9858 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0580 │     0.9829 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0880 │     0.9720 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   2\n",
            "Training: 100% 31/31 [00:01<00:00, 18.87it/s]\n",
            "Evaluation train: 100% 31/31 [00:00<00:00, 63.96it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 75.84it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 67.27it/s]\n",
            "Took 2.3313s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0105 │     0.9990 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0377 │     0.9886 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0667 │     0.9810 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   3\n",
            "Training: 100% 31/31 [00:01<00:00, 18.73it/s]\n",
            "Evaluation train: 100% 31/31 [00:00<00:00, 65.25it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 76.48it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 67.51it/s]\n",
            "Took 2.3338s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0037 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0398 │     0.9886 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0760 │     0.9756 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 1 epoch ago\n",
            "\n",
            "\n",
            "Epoch   4\n",
            "Training: 100% 31/31 [00:01<00:00, 18.85it/s]\n",
            "Evaluation train: 100% 31/31 [00:00<00:00, 65.16it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 77.29it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 66.80it/s]\n",
            "Took 2.3239s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0021 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0383 │     0.9905 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0763 │     0.9765 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 2 epochs ago\n",
            "\n",
            "\n",
            "Epoch   5\n",
            "Training: 100% 31/31 [00:01<00:00, 18.77it/s]\n",
            "Evaluation train: 100% 31/31 [00:00<00:00, 65.14it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 73.79it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 64.45it/s]\n",
            "Took 2.3404s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0018 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0481 │     0.9810 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0947 │     0.9756 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 3 epochs ago\n",
            "\n",
            "\n",
            "Epoch   6\n",
            "Training: 100% 31/31 [00:01<00:00, 18.74it/s]\n",
            "Evaluation train: 100% 31/31 [00:00<00:00, 63.70it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 72.26it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 66.61it/s]\n",
            "Took 2.3497s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0010 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0361 │     0.9924 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0756 │     0.9774 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   7\n",
            "Training: 100% 31/31 [00:01<00:00, 18.62it/s]\n",
            "Evaluation train: 100% 31/31 [00:00<00:00, 63.68it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 76.69it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 66.57it/s]\n",
            "Took 2.3588s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0008 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0342 │     0.9924 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0731 │     0.9774 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   8\n",
            "Training: 100% 31/31 [00:01<00:00, 18.60it/s]\n",
            "Evaluation train: 100% 31/31 [00:00<00:00, 64.16it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 71.94it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 66.93it/s]\n",
            "Took 2.3589s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0007 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0332 │     0.9924 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0722 │     0.9783 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch   9\n",
            "Training: 100% 31/31 [00:01<00:00, 18.62it/s]\n",
            "Evaluation train: 100% 31/31 [00:00<00:00, 64.56it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 76.14it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 66.47it/s]\n",
            "Took 2.3503s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0005 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0322 │     0.9924 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0714 │     0.9810 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  10\n",
            "Training: 100% 31/31 [00:01<00:00, 18.67it/s]\n",
            "Evaluation train: 100% 31/31 [00:00<00:00, 63.96it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 75.95it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 67.20it/s]\n",
            "Took 2.3492s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0004 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0318 │     0.9924 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0718 │     0.9810 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  11\n",
            "Training: 100% 31/31 [00:01<00:00, 18.59it/s]\n",
            "Evaluation train: 100% 31/31 [00:00<00:00, 63.94it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 75.47it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 66.81it/s]\n",
            "Took 2.3581s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0003 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0321 │     0.9924 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0731 │     0.9801 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 1 epoch ago\n",
            "\n",
            "\n",
            "Epoch  12\n",
            "Training: 100% 31/31 [00:01<00:00, 18.61it/s]\n",
            "Evaluation train: 100% 31/31 [00:00<00:00, 62.87it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 76.00it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 66.67it/s]\n",
            "Took 2.3652s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0002 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0331 │     0.9924 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0761 │     0.9792 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 2 epochs ago\n",
            "\n",
            "\n",
            "Epoch  13\n",
            "Training: 100% 31/31 [00:01<00:00, 18.46it/s]\n",
            "Evaluation train: 100% 31/31 [00:00<00:00, 63.81it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 75.39it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 66.90it/s]\n",
            "Took 2.3700s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0002 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0351 │     0.9924 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0813 │     0.9783 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 3 epochs ago\n",
            "\n",
            "\n",
            "Epoch  14\n",
            "Training: 100% 31/31 [00:01<00:00, 18.40it/s]\n",
            "Evaluation train: 100% 31/31 [00:00<00:00, 63.63it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 75.75it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 66.23it/s]\n",
            "Took 2.3783s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0001 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0381 │     0.9924 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0881 │     0.9765 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 4 epochs ago\n",
            "\n",
            "\n",
            "Epoch  15\n",
            "Training: 100% 31/31 [00:01<00:00, 18.43it/s]\n",
            "Evaluation train: 100% 31/31 [00:00<00:00, 63.70it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 74.98it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 65.96it/s]\n",
            "Took 2.3772s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0001 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0412 │     0.9924 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0946 │     0.9765 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 5 epochs ago\n",
            "\n",
            "EARLY STOPPING due to lack of validation improvement, it has been 5 epochs since last validation accuracy improvement\n",
            "\n",
            "Best validation model epoch:\n",
            "Best validation model loss on validation set combined: 0.03184508212265514\n",
            "Best validation model loss on test set combined: 0.07177265217050319\n",
            "\n",
            "Finished: experiment_run\n",
            "Saved to: results/experiment_run_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWT5Q5okhwtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6531
        },
        "outputId": "53f5ed3c-9807-467f-bbae-cff6d245fb71"
      },
      "source": [
        "!ludwig train --data_csv spam1.csv --model_definition \"{input_features: [{name: text, type: text, encoder: rnn}], output_features: [{name: label, type: category}], training: {epochs: 50}}\"\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            " _         _        _      \n",
            "| |_  _ __| |_ __ _(_)__ _ \n",
            "| | || / _` \\ V  V / / _` |\n",
            "|_|\\_,_\\__,_|\\_/\\_/|_\\__, |\n",
            "                     |___/ \n",
            "ludwig v0.1.2 - Train\n",
            "\n",
            "Experiment name: experiment\n",
            "Model name: run\n",
            "Output path: results/experiment_run_1\n",
            "\n",
            "\n",
            "ludwig_version: '0.1.2'\n",
            "command: ('/usr/local/bin/ludwig train --data_csv spam1.csv --model_definition '\n",
            " '{input_features: [{name: text, type: text, encoder: rnn}], output_features: '\n",
            " '[{name: label, type: category}], training: {epochs: 50}}')\n",
            "random_seed: 42\n",
            "input_data: 'spam1.csv'\n",
            "model_definition: {   'combiner': {'type': 'concat'},\n",
            "    'input_features': [   {   'encoder': 'rnn',\n",
            "                              'level': 'word',\n",
            "                              'name': 'text',\n",
            "                              'tied_weights': None,\n",
            "                              'type': 'text'}],\n",
            "    'output_features': [   {   'dependencies': [],\n",
            "                               'loss': {   'class_similarities_temperature': 0,\n",
            "                                           'class_weights': 1,\n",
            "                                           'confidence_penalty': 0,\n",
            "                                           'distortion': 1,\n",
            "                                           'labels_smoothing': 0,\n",
            "                                           'negative_samples': 0,\n",
            "                                           'robust_lambda': 0,\n",
            "                                           'sampler': None,\n",
            "                                           'type': 'softmax_cross_entropy',\n",
            "                                           'unique': False,\n",
            "                                           'weight': 1},\n",
            "                               'name': 'label',\n",
            "                               'reduce_dependencies': 'sum',\n",
            "                               'reduce_input': 'sum',\n",
            "                               'top_k': 3,\n",
            "                               'type': 'category'}],\n",
            "    'preprocessing': {   'bag': {   'fill_value': '',\n",
            "                                    'format': 'space',\n",
            "                                    'lowercase': False,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': 10000},\n",
            "                         'binary': {   'fill_value': 0,\n",
            "                                       'missing_value_strategy': 'fill_with_const'},\n",
            "                         'category': {   'fill_value': '<UNK>',\n",
            "                                         'lowercase': False,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 10000},\n",
            "                         'force_split': False,\n",
            "                         'image': {   'in_memory': True,\n",
            "                                      'missing_value_strategy': 'backfill',\n",
            "                                      'resize_method': 'crop_or_pad'},\n",
            "                         'numerical': {   'fill_value': 0,\n",
            "                                          'missing_value_strategy': 'fill_with_const'},\n",
            "                         'sequence': {   'fill_value': '',\n",
            "                                         'format': 'space',\n",
            "                                         'lowercase': False,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 20000,\n",
            "                                         'padding': 'right',\n",
            "                                         'padding_symbol': '<PAD>',\n",
            "                                         'sequence_length_limit': 256,\n",
            "                                         'unknown_symbol': '<UNK>'},\n",
            "                         'set': {   'fill_value': '',\n",
            "                                    'format': 'space',\n",
            "                                    'lowercase': False,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': 10000},\n",
            "                         'split_probabilities': (0.7, 0.1, 0.2),\n",
            "                         'stratify': None,\n",
            "                         'text': {   'char_format': 'characters',\n",
            "                                     'char_most_common': 70,\n",
            "                                     'char_sequence_length_limit': 1024,\n",
            "                                     'fill_value': '',\n",
            "                                     'lowercase': True,\n",
            "                                     'missing_value_strategy': 'fill_with_const',\n",
            "                                     'padding': 'right',\n",
            "                                     'padding_symbol': '<PAD>',\n",
            "                                     'unknown_symbol': '<UNK>',\n",
            "                                     'word_format': 'space_punct',\n",
            "                                     'word_most_common': 20000,\n",
            "                                     'word_sequence_length_limit': 256},\n",
            "                         'timeseries': {   'fill_value': '',\n",
            "                                           'format': 'space',\n",
            "                                           'missing_value_strategy': 'fill_with_const',\n",
            "                                           'padding': 'right',\n",
            "                                           'padding_value': 0,\n",
            "                                           'timeseries_length_limit': 256}},\n",
            "    'training': {   'batch_size': 128,\n",
            "                    'bucketing_field': None,\n",
            "                    'decay': False,\n",
            "                    'decay_rate': 0.96,\n",
            "                    'decay_steps': 10000,\n",
            "                    'dropout_rate': 0.0,\n",
            "                    'early_stop': 5,\n",
            "                    'epochs': 50,\n",
            "                    'eval_batch_size': 0,\n",
            "                    'gradient_clipping': None,\n",
            "                    'increase_batch_size_on_plateau': 0,\n",
            "                    'increase_batch_size_on_plateau_max': 512,\n",
            "                    'increase_batch_size_on_plateau_patience': 5,\n",
            "                    'increase_batch_size_on_plateau_rate': 2,\n",
            "                    'learning_rate': 0.001,\n",
            "                    'learning_rate_warmup_epochs': 5,\n",
            "                    'optimizer': {   'beta1': 0.9,\n",
            "                                     'beta2': 0.999,\n",
            "                                     'epsilon': 1e-08,\n",
            "                                     'type': 'adam'},\n",
            "                    'reduce_learning_rate_on_plateau': 0,\n",
            "                    'reduce_learning_rate_on_plateau_patience': 5,\n",
            "                    'reduce_learning_rate_on_plateau_rate': 0.5,\n",
            "                    'regularization_lambda': 0,\n",
            "                    'regularizer': 'l2',\n",
            "                    'staircase': False,\n",
            "                    'validation_field': 'combined',\n",
            "                    'validation_measure': 'loss'}}\n",
            "\n",
            "\n",
            "Found hdf5 and json with the same filename of the csv, using them instead\n",
            "Using full hdf5 and json\n",
            "Loading data from: spam1.hdf5\n",
            "Loading metadata from: spam1.json\n",
            "Training set: 3939\n",
            "Validation set: 525\n",
            "Test set: 1108\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/ludwig/models/modules/recurrent_modules.py:201: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "From /usr/local/lib/python3.6/dist-packages/ludwig/models/modules/recurrent_modules.py:201: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/ludwig/models/modules/recurrent_modules.py:204: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "From /usr/local/lib/python3.6/dist-packages/ludwig/models/modules/recurrent_modules.py:204: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/ludwig/models/modules/recurrent_modules.py:209: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "From /usr/local/lib/python3.6/dist-packages/ludwig/models/modules/recurrent_modules.py:209: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "\n",
            "╒══════════╕\n",
            "│ TRAINING │\n",
            "╘══════════╛\n",
            "\n",
            "2019-05-21 22:34:07.288966: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-05-21 22:34:07.289174: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x26b3020 executing computations on platform Host. Devices:\n",
            "2019-05-21 22:34:07.289210: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-05-21 22:34:07.416330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-05-21 22:34:07.416832: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x26b2ec0 executing computations on platform CUDA. Devices:\n",
            "2019-05-21 22:34:07.416861: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-05-21 22:34:07.417198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-05-21 22:34:07.417221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-05-21 22:34:07.878780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-05-21 22:34:07.878843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-05-21 22:34:07.878855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-05-21 22:34:07.879102: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-05-21 22:34:07.879150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "\n",
            "Epoch  1\n",
            "Training:   0% 0/31 [00:00<?, ?it/s]2019-05-21 22:34:08.306665: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "Training: 100% 31/31 [00:03<00:00, 10.19it/s]\n",
            "Evaluation train: 100% 31/31 [00:01<00:00, 26.42it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 31.21it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 29.61it/s]\n",
            "Took 4.6968s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.1663 │     0.9403 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.1857 │     0.9257 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.2211 │     0.9197 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  2\n",
            "Training: 100% 31/31 [00:02<00:00, 13.14it/s]\n",
            "Evaluation train: 100% 31/31 [00:01<00:00, 26.96it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 35.14it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 31.89it/s]\n",
            "Took 4.3765s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.1054 │     0.9614 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.1469 │     0.9562 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.1935 │     0.9449 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  3\n",
            "Training: 100% 31/31 [00:02<00:00, 12.85it/s]\n",
            "Evaluation train: 100% 31/31 [00:01<00:00, 27.70it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 37.39it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 31.53it/s]\n",
            "Took 3.9547s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0268 │     0.9934 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0816 │     0.9771 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0984 │     0.9738 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  4\n",
            "Training: 100% 31/31 [00:02<00:00, 13.46it/s]\n",
            "Evaluation train: 100% 31/31 [00:01<00:00, 27.30it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 38.54it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 30.51it/s]\n",
            "Took 3.8675s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0236 │     0.9909 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0814 │     0.9714 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0893 │     0.9756 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  5\n",
            "Training: 100% 31/31 [00:02<00:00, 13.29it/s]\n",
            "Evaluation train: 100% 31/31 [00:01<00:00, 27.99it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 36.29it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 23.64it/s]\n",
            "Took 3.9100s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0093 │     0.9967 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0633 │     0.9810 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0746 │     0.9819 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  6\n",
            "Training: 100% 31/31 [00:02<00:00, 13.03it/s]\n",
            "Evaluation train: 100% 31/31 [00:01<00:00, 28.96it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 37.94it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 30.35it/s]\n",
            "Took 3.9049s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0030 │     0.9995 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0808 │     0.9790 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.1015 │     0.9792 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 1 epoch ago\n",
            "\n",
            "\n",
            "Epoch  7\n",
            "Training: 100% 31/31 [00:02<00:00, 13.75it/s]\n",
            "Evaluation train: 100% 31/31 [00:01<00:00, 29.33it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 37.91it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 30.87it/s]\n",
            "Took 3.7407s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0015 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0744 │     0.9810 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0862 │     0.9783 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 2 epochs ago\n",
            "\n",
            "\n",
            "Epoch  8\n",
            "Training: 100% 31/31 [00:02<00:00, 12.84it/s]\n",
            "Evaluation train: 100% 31/31 [00:01<00:00, 26.14it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 33.67it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 20.14it/s]\n",
            "Took 4.1732s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0010 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0797 │     0.9771 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0785 │     0.9783 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 3 epochs ago\n",
            "\n",
            "\n",
            "Epoch  9\n",
            "Training: 100% 31/31 [00:02<00:00, 12.58it/s]\n",
            "Evaluation train: 100% 31/31 [00:01<00:00, 25.08it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 29.73it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 27.57it/s]\n",
            "Took 4.3459s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0006 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0762 │     0.9848 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0838 │     0.9838 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 4 epochs ago\n",
            "\n",
            "\n",
            "Epoch 10\n",
            "Training: 100% 31/31 [00:02<00:00, 12.57it/s]\n",
            "Evaluation train: 100% 31/31 [00:01<00:00, 25.77it/s]\n",
            "Evaluation vali : 100% 5/5 [00:00<00:00, 30.20it/s]\n",
            "Evaluation test : 100% 9/9 [00:00<00:00, 21.68it/s]\n",
            "Took 4.3907s\n",
            "╒═════════╤════════╤════════════╤═════════════╕\n",
            "│ label   │   loss │   accuracy │   hits_at_k │\n",
            "╞═════════╪════════╪════════════╪═════════════╡\n",
            "│ train   │ 0.0004 │     1.0000 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ vali    │ 0.0783 │     0.9848 │      1.0000 │\n",
            "├─────────┼────────┼────────────┼─────────────┤\n",
            "│ test    │ 0.0820 │     0.9838 │      1.0000 │\n",
            "╘═════════╧════════╧════════════╧═════════════╛\n",
            "Last improvement of loss on combined happened 5 epochs ago\n",
            "\n",
            "EARLY STOPPING due to lack of validation improvement, it has been 5 epochs since last validation accuracy improvement\n",
            "\n",
            "Best validation model epoch:\n",
            "Best validation model loss on validation set combined: 0.06328182072866531\n",
            "Best validation model loss on test set combined: 0.07460914191786563\n",
            "\n",
            "Finished: experiment_run\n",
            "Saved to: results/experiment_run_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EgcqTx3iFvo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "908a473a-cc30-4f5a-98b4-b592b0bf9203"
      },
      "source": [
        "!ludwig visualize --visualization learning_curves --training_statistics results/experiment_run_0/training_statistics.json\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LK3U7SwQOg2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "574573d6-8748-4100-c19f-6b60feba02cd"
      },
      "source": [
        "!ludwig visualize --visualization learning_curves --training_statistics results/experiment_run_1/training_statistics.json\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n",
            "<Figure size 640x480 with 1 Axes>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQQGkL1QQOny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://aic.ai.wu.ac.at/~wohlg/cooking.stackexchange.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBBz2MbZQOqz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5953
        },
        "outputId": "a74fb036-ce4d-43a8-ade6-9521743915ff"
      },
      "source": [
        "!ludwig train --data_csv  cooking.stackexchange.csv --model_definition \"{input_features: [{name: text, type: text, encoder: rnn}], output_features: [{name: labels, type: set}], training: {epochs: 50}}\"\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            " _         _        _      \n",
            "| |_  _ __| |_ __ _(_)__ _ \n",
            "| | || / _` \\ V  V / / _` |\n",
            "|_|\\_,_\\__,_|\\_/\\_/|_\\__, |\n",
            "                     |___/ \n",
            "ludwig v0.1.2 - Train\n",
            "\n",
            "Experiment name: experiment\n",
            "Model name: run\n",
            "Output path: results/experiment_run_3\n",
            "\n",
            "\n",
            "ludwig_version: '0.1.2'\n",
            "command: ('/usr/local/bin/ludwig train --data_csv cooking.stackexchange.csv '\n",
            " '--model_definition {input_features: [{name: text, type: text, encoder: '\n",
            " 'rnn}], output_features: [{name: labels, type: set}], training: {epochs: 50}}')\n",
            "random_seed: 42\n",
            "input_data: 'cooking.stackexchange.csv'\n",
            "model_definition: {   'combiner': {'type': 'concat'},\n",
            "    'input_features': [   {   'encoder': 'rnn',\n",
            "                              'level': 'word',\n",
            "                              'name': 'text',\n",
            "                              'tied_weights': None,\n",
            "                              'type': 'text'}],\n",
            "    'output_features': [   {   'dependencies': [],\n",
            "                               'loss': {'type': None, 'weight': 1},\n",
            "                               'name': 'labels',\n",
            "                               'reduce_dependencies': 'sum',\n",
            "                               'reduce_input': 'sum',\n",
            "                               'threshold': 0.5,\n",
            "                               'type': 'set'}],\n",
            "    'preprocessing': {   'bag': {   'fill_value': '',\n",
            "                                    'format': 'space',\n",
            "                                    'lowercase': False,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': 10000},\n",
            "                         'binary': {   'fill_value': 0,\n",
            "                                       'missing_value_strategy': 'fill_with_const'},\n",
            "                         'category': {   'fill_value': '<UNK>',\n",
            "                                         'lowercase': False,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 10000},\n",
            "                         'force_split': False,\n",
            "                         'image': {   'in_memory': True,\n",
            "                                      'missing_value_strategy': 'backfill',\n",
            "                                      'resize_method': 'crop_or_pad'},\n",
            "                         'numerical': {   'fill_value': 0,\n",
            "                                          'missing_value_strategy': 'fill_with_const'},\n",
            "                         'sequence': {   'fill_value': '',\n",
            "                                         'format': 'space',\n",
            "                                         'lowercase': False,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 20000,\n",
            "                                         'padding': 'right',\n",
            "                                         'padding_symbol': '<PAD>',\n",
            "                                         'sequence_length_limit': 256,\n",
            "                                         'unknown_symbol': '<UNK>'},\n",
            "                         'set': {   'fill_value': '',\n",
            "                                    'format': 'space',\n",
            "                                    'lowercase': False,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': 10000},\n",
            "                         'split_probabilities': (0.7, 0.1, 0.2),\n",
            "                         'stratify': None,\n",
            "                         'text': {   'char_format': 'characters',\n",
            "                                     'char_most_common': 70,\n",
            "                                     'char_sequence_length_limit': 1024,\n",
            "                                     'fill_value': '',\n",
            "                                     'lowercase': True,\n",
            "                                     'missing_value_strategy': 'fill_with_const',\n",
            "                                     'padding': 'right',\n",
            "                                     'padding_symbol': '<PAD>',\n",
            "                                     'unknown_symbol': '<UNK>',\n",
            "                                     'word_format': 'space_punct',\n",
            "                                     'word_most_common': 20000,\n",
            "                                     'word_sequence_length_limit': 256},\n",
            "                         'timeseries': {   'fill_value': '',\n",
            "                                           'format': 'space',\n",
            "                                           'missing_value_strategy': 'fill_with_const',\n",
            "                                           'padding': 'right',\n",
            "                                           'padding_value': 0,\n",
            "                                           'timeseries_length_limit': 256}},\n",
            "    'training': {   'batch_size': 128,\n",
            "                    'bucketing_field': None,\n",
            "                    'decay': False,\n",
            "                    'decay_rate': 0.96,\n",
            "                    'decay_steps': 10000,\n",
            "                    'dropout_rate': 0.0,\n",
            "                    'early_stop': 5,\n",
            "                    'epochs': 50,\n",
            "                    'eval_batch_size': 0,\n",
            "                    'gradient_clipping': None,\n",
            "                    'increase_batch_size_on_plateau': 0,\n",
            "                    'increase_batch_size_on_plateau_max': 512,\n",
            "                    'increase_batch_size_on_plateau_patience': 5,\n",
            "                    'increase_batch_size_on_plateau_rate': 2,\n",
            "                    'learning_rate': 0.001,\n",
            "                    'learning_rate_warmup_epochs': 5,\n",
            "                    'optimizer': {   'beta1': 0.9,\n",
            "                                     'beta2': 0.999,\n",
            "                                     'epsilon': 1e-08,\n",
            "                                     'type': 'adam'},\n",
            "                    'reduce_learning_rate_on_plateau': 0,\n",
            "                    'reduce_learning_rate_on_plateau_patience': 5,\n",
            "                    'reduce_learning_rate_on_plateau_rate': 0.5,\n",
            "                    'regularization_lambda': 0,\n",
            "                    'regularizer': 'l2',\n",
            "                    'staircase': False,\n",
            "                    'validation_field': 'combined',\n",
            "                    'validation_measure': 'loss'}}\n",
            "\n",
            "\n",
            "Found hdf5 and json with the same filename of the csv, using them instead\n",
            "Using full hdf5 and json\n",
            "Loading data from: cooking.stackexchange.hdf5\n",
            "Loading metadata from: cooking.stackexchange.json\n",
            "Training set: 10875\n",
            "Validation set: 1453\n",
            "Test set: 3076\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/ludwig/models/modules/recurrent_modules.py:201: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "From /usr/local/lib/python3.6/dist-packages/ludwig/models/modules/recurrent_modules.py:201: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/ludwig/models/modules/recurrent_modules.py:204: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "From /usr/local/lib/python3.6/dist-packages/ludwig/models/modules/recurrent_modules.py:204: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/ludwig/models/modules/recurrent_modules.py:209: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "From /usr/local/lib/python3.6/dist-packages/ludwig/models/modules/recurrent_modules.py:209: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "\n",
            "╒══════════╕\n",
            "│ TRAINING │\n",
            "╘══════════╛\n",
            "\n",
            "2019-05-21 22:55:27.883783: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-05-21 22:55:27.884192: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2095020 executing computations on platform Host. Devices:\n",
            "2019-05-21 22:55:27.884229: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-05-21 22:55:28.011051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-05-21 22:55:28.011572: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2094ec0 executing computations on platform CUDA. Devices:\n",
            "2019-05-21 22:55:28.011601: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-05-21 22:55:28.011959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-05-21 22:55:28.011980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-05-21 22:55:28.455739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-05-21 22:55:28.455804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-05-21 22:55:28.455816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-05-21 22:55:28.456057: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-05-21 22:55:28.456106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "\n",
            "Epoch  1\n",
            "Training:   0% 0/85 [00:00<?, ?it/s]2019-05-21 22:55:28.828090: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "Training: 100% 85/85 [00:02<00:00, 40.47it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 94.81it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 100.52it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 96.62it/s]\n",
            "Took 3.3926s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 15.9835 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 17.0889 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 17.9920 │    0.0000 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  2\n",
            "Training: 100% 85/85 [00:01<00:00, 54.27it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 98.12it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 101.81it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 102.47it/s]\n",
            "Took 2.7983s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 14.0618 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 15.3445 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 15.9044 │    0.0000 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  3\n",
            "Training: 100% 85/85 [00:01<00:00, 51.65it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 97.86it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 100.43it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 108.96it/s]\n",
            "Took 2.8672s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 13.6736 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 14.9912 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 15.3333 │    0.0000 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  4\n",
            "Training: 100% 85/85 [00:01<00:00, 50.52it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 98.26it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 102.22it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 102.93it/s]\n",
            "Took 2.9118s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 13.6843 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 14.8562 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 15.1089 │    0.0000 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  5\n",
            "Training: 100% 85/85 [00:01<00:00, 52.21it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 99.43it/s] \n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 106.82it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 102.07it/s]\n",
            "Took 2.8442s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 14.5554 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 18.1711 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 15.8359 │    0.0001 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Last improvement of loss on combined happened 1 epoch ago\n",
            "\n",
            "\n",
            "Epoch  6\n",
            "Training: 100% 85/85 [00:01<00:00, 50.96it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 101.18it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 96.88it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 101.98it/s]\n",
            "Took 2.8807s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 13.5689 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 14.9939 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 14.7306 │    0.0000 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Last improvement of loss on combined happened 2 epochs ago\n",
            "\n",
            "\n",
            "Epoch  7\n",
            "Training: 100% 85/85 [00:01<00:00, 53.79it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 99.05it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 105.45it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 99.58it/s] \n",
            "Took 2.8072s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 13.4005 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 15.4465 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 14.5653 │    0.0000 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Last improvement of loss on combined happened 3 epochs ago\n",
            "\n",
            "\n",
            "Epoch  8\n",
            "Training: 100% 85/85 [00:01<00:00, 52.25it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 99.09it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 105.63it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 105.69it/s]\n",
            "Took 2.8385s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 13.3627 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 16.0436 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 14.5644 │    0.0000 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Last improvement of loss on combined happened 4 epochs ago\n",
            "\n",
            "\n",
            "Epoch  9\n",
            "Training: 100% 85/85 [00:01<00:00, 46.95it/s]\n",
            "Evaluation train: 100% 85/85 [00:01<00:00, 84.25it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 84.60it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 83.17it/s]\n",
            "Took 3.2668s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 13.3377 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 16.7792 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 14.5968 │    0.0000 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Last improvement of loss on combined happened 5 epochs ago\n",
            "\n",
            "EARLY STOPPING due to lack of validation improvement, it has been 5 epochs since last validation accuracy improvement\n",
            "\n",
            "Best validation model epoch:\n",
            "Best validation model loss on validation set combined: 14.856241119867837\n",
            "Best validation model loss on test set combined: 15.108932414507525\n",
            "\n",
            "Finished: experiment_run\n",
            "Saved to: results/experiment_run_3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SH8xkF9oL_d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6701
        },
        "outputId": "c75a7f49-4f4e-4e1c-dfb6-582e534705b7"
      },
      "source": [
        "!ludwig train --data_csv  cooking.stackexchange.csv --model_definition \"{input_features: [{name: text, type: text}], output_features: [{name: labels, type: set, embedding_size: 100}], training: {epochs: 50}}\"\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            " _         _        _      \n",
            "| |_  _ __| |_ __ _(_)__ _ \n",
            "| | || / _` \\ V  V / / _` |\n",
            "|_|\\_,_\\__,_|\\_/\\_/|_\\__, |\n",
            "                     |___/ \n",
            "ludwig v0.1.2 - Train\n",
            "\n",
            "Experiment name: experiment\n",
            "Model name: run\n",
            "Output path: results/experiment_run_11\n",
            "\n",
            "\n",
            "ludwig_version: '0.1.2'\n",
            "command: ('/usr/local/bin/ludwig train --data_csv cooking.stackexchange.csv '\n",
            " '--model_definition {input_features: [{name: text, type: text}], '\n",
            " 'output_features: [{name: labels, type: set, embedding_size: 100}], training: '\n",
            " '{epochs: 50}}')\n",
            "random_seed: 42\n",
            "input_data: 'cooking.stackexchange.csv'\n",
            "model_definition: {   'combiner': {'type': 'concat'},\n",
            "    'input_features': [   {   'encoder': 'parallel_cnn',\n",
            "                              'level': 'word',\n",
            "                              'name': 'text',\n",
            "                              'tied_weights': None,\n",
            "                              'type': 'text'}],\n",
            "    'output_features': [   {   'dependencies': [],\n",
            "                               'embedding_size': 100,\n",
            "                               'loss': {'type': None, 'weight': 1},\n",
            "                               'name': 'labels',\n",
            "                               'reduce_dependencies': 'sum',\n",
            "                               'reduce_input': 'sum',\n",
            "                               'threshold': 0.5,\n",
            "                               'type': 'set'}],\n",
            "    'preprocessing': {   'bag': {   'fill_value': '',\n",
            "                                    'format': 'space',\n",
            "                                    'lowercase': False,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': 10000},\n",
            "                         'binary': {   'fill_value': 0,\n",
            "                                       'missing_value_strategy': 'fill_with_const'},\n",
            "                         'category': {   'fill_value': '<UNK>',\n",
            "                                         'lowercase': False,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 10000},\n",
            "                         'force_split': False,\n",
            "                         'image': {   'in_memory': True,\n",
            "                                      'missing_value_strategy': 'backfill',\n",
            "                                      'resize_method': 'crop_or_pad'},\n",
            "                         'numerical': {   'fill_value': 0,\n",
            "                                          'missing_value_strategy': 'fill_with_const'},\n",
            "                         'sequence': {   'fill_value': '',\n",
            "                                         'format': 'space',\n",
            "                                         'lowercase': False,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 20000,\n",
            "                                         'padding': 'right',\n",
            "                                         'padding_symbol': '<PAD>',\n",
            "                                         'sequence_length_limit': 256,\n",
            "                                         'unknown_symbol': '<UNK>'},\n",
            "                         'set': {   'fill_value': '',\n",
            "                                    'format': 'space',\n",
            "                                    'lowercase': False,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': 10000},\n",
            "                         'split_probabilities': (0.7, 0.1, 0.2),\n",
            "                         'stratify': None,\n",
            "                         'text': {   'char_format': 'characters',\n",
            "                                     'char_most_common': 70,\n",
            "                                     'char_sequence_length_limit': 1024,\n",
            "                                     'fill_value': '',\n",
            "                                     'lowercase': True,\n",
            "                                     'missing_value_strategy': 'fill_with_const',\n",
            "                                     'padding': 'right',\n",
            "                                     'padding_symbol': '<PAD>',\n",
            "                                     'unknown_symbol': '<UNK>',\n",
            "                                     'word_format': 'space_punct',\n",
            "                                     'word_most_common': 20000,\n",
            "                                     'word_sequence_length_limit': 256},\n",
            "                         'timeseries': {   'fill_value': '',\n",
            "                                           'format': 'space',\n",
            "                                           'missing_value_strategy': 'fill_with_const',\n",
            "                                           'padding': 'right',\n",
            "                                           'padding_value': 0,\n",
            "                                           'timeseries_length_limit': 256}},\n",
            "    'training': {   'batch_size': 128,\n",
            "                    'bucketing_field': None,\n",
            "                    'decay': False,\n",
            "                    'decay_rate': 0.96,\n",
            "                    'decay_steps': 10000,\n",
            "                    'dropout_rate': 0.0,\n",
            "                    'early_stop': 5,\n",
            "                    'epochs': 50,\n",
            "                    'eval_batch_size': 0,\n",
            "                    'gradient_clipping': None,\n",
            "                    'increase_batch_size_on_plateau': 0,\n",
            "                    'increase_batch_size_on_plateau_max': 512,\n",
            "                    'increase_batch_size_on_plateau_patience': 5,\n",
            "                    'increase_batch_size_on_plateau_rate': 2,\n",
            "                    'learning_rate': 0.001,\n",
            "                    'learning_rate_warmup_epochs': 5,\n",
            "                    'optimizer': {   'beta1': 0.9,\n",
            "                                     'beta2': 0.999,\n",
            "                                     'epsilon': 1e-08,\n",
            "                                     'type': 'adam'},\n",
            "                    'reduce_learning_rate_on_plateau': 0,\n",
            "                    'reduce_learning_rate_on_plateau_patience': 5,\n",
            "                    'reduce_learning_rate_on_plateau_rate': 0.5,\n",
            "                    'regularization_lambda': 0,\n",
            "                    'regularizer': 'l2',\n",
            "                    'staircase': False,\n",
            "                    'validation_field': 'combined',\n",
            "                    'validation_measure': 'loss'}}\n",
            "\n",
            "\n",
            "Found hdf5 and json with the same filename of the csv, using them instead\n",
            "Using full hdf5 and json\n",
            "Loading data from: cooking.stackexchange.hdf5\n",
            "Loading metadata from: cooking.stackexchange.json\n",
            "Training set: 10875\n",
            "Validation set: 1453\n",
            "Test set: 3076\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "\n",
            "╒══════════╕\n",
            "│ TRAINING │\n",
            "╘══════════╛\n",
            "\n",
            "2019-05-21 23:23:56.121951: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-05-21 23:23:56.122318: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x177d700 executing computations on platform Host. Devices:\n",
            "2019-05-21 23:23:56.122351: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-05-21 23:23:56.246371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-05-21 23:23:56.246882: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x177d2e0 executing computations on platform CUDA. Devices:\n",
            "2019-05-21 23:23:56.246911: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-05-21 23:23:56.247241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-05-21 23:23:56.247263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-05-21 23:23:56.693146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-05-21 23:23:56.693203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-05-21 23:23:56.693215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-05-21 23:23:56.693463: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-05-21 23:23:56.693503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "\n",
            "Epoch  1\n",
            "Training:   0% 0/85 [00:00<?, ?it/s]2019-05-21 23:23:57.287373: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "Training: 100% 85/85 [00:06<00:00,  7.01it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 228.96it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 30.22it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 68.92it/s] \n",
            "Took 7.8766s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 13.8594 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 14.6536 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 14.1178 │    0.0000 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  2\n",
            "Training: 100% 85/85 [00:01<00:00, 66.77it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 251.11it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 255.69it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 263.24it/s]\n",
            "Took 1.7575s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 12.7024 │    0.0045 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 13.8637 │    0.0046 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 13.3568 │    0.0028 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  3\n",
            "Training: 100% 85/85 [00:01<00:00, 68.20it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 244.68it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 258.09it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 262.06it/s]\n",
            "Took 1.7397s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 11.2879 │    0.0602 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 12.9129 │    0.0481 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 12.4496 │    0.0498 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  4\n",
            "Training: 100% 85/85 [00:01<00:00, 67.10it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 248.80it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 263.32it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 256.55it/s]\n",
            "Took 1.7554s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │  9.8286 │    0.1410 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 11.9817 │    0.1031 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 11.5848 │    0.1054 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  5\n",
            "Training: 100% 85/85 [00:01<00:00, 67.50it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 246.95it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 263.26it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 261.07it/s]\n",
            "Took 1.7579s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │  8.5290 │    0.2058 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 11.3949 │    0.1414 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 11.0205 │    0.1414 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  6\n",
            "Training: 100% 85/85 [00:01<00:00, 67.67it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 241.13it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 249.91it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 251.55it/s]\n",
            "Took 1.7634s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │  7.2964 │    0.2774 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 11.0244 │    0.1669 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 10.6610 │    0.1671 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  7\n",
            "Training: 100% 85/85 [00:01<00:00, 65.87it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 243.18it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 255.51it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 242.05it/s]\n",
            "Took 1.7957s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │  6.2671 │    0.3525 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 10.8135 │    0.1910 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 10.4545 │    0.1921 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  8\n",
            "Training: 100% 85/85 [00:01<00:00, 66.22it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 239.40it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 256.92it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 243.14it/s]\n",
            "Took 1.7943s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │  5.8277 │    0.4616 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 10.8537 │    0.2295 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 10.5629 │    0.2348 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Last improvement of loss on combined happened 1 epoch ago\n",
            "\n",
            "\n",
            "Epoch  9\n",
            "Training: 100% 85/85 [00:01<00:00, 65.90it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 237.18it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 247.08it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 252.59it/s]\n",
            "Took 1.8003s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │  4.7396 │    0.5332 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 10.8473 │    0.2229 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 10.5578 │    0.2333 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Last improvement of loss on combined happened 2 epochs ago\n",
            "\n",
            "\n",
            "Epoch 10\n",
            "Training: 100% 85/85 [00:01<00:00, 66.30it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 238.14it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 245.83it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 249.08it/s]\n",
            "Took 1.7926s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │  5.0961 │    0.3889 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 13.6525 │    0.1477 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 13.2415 │    0.1586 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Last improvement of loss on combined happened 3 epochs ago\n",
            "\n",
            "\n",
            "Epoch 11\n",
            "Training: 100% 85/85 [00:01<00:00, 66.10it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 244.47it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 237.21it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 259.25it/s]\n",
            "Took 1.7850s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │  4.4850 │    0.4355 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 14.4024 │    0.1692 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 13.8025 │    0.1746 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Last improvement of loss on combined happened 4 epochs ago\n",
            "\n",
            "\n",
            "Epoch 12\n",
            "Training: 100% 85/85 [00:01<00:00, 66.58it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 237.77it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 257.45it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 246.76it/s]\n",
            "Took 1.7862s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │  3.2726 │    0.6758 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 11.9295 │    0.2516 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 11.4852 │    0.2565 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Last improvement of loss on combined happened 5 epochs ago\n",
            "\n",
            "EARLY STOPPING due to lack of validation improvement, it has been 5 epochs since last validation accuracy improvement\n",
            "\n",
            "Best validation model epoch:\n",
            "Best validation model loss on validation set combined: 10.813460264054973\n",
            "Best validation model loss on test set combined: 10.45446678627917\n",
            "\n",
            "Finished: experiment_run\n",
            "Saved to: results/experiment_run_11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcUL4HEGrjVg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "186cac04-cbba-41bd-f49e-0bbe4036ce02"
      },
      "source": [
        "!wget https://aic.ai.wu.ac.at/~wohlg/glove.6B.100d.txt"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-21 23:18:33--  https://aic.ai.wu.ac.at/~wohlg/glove.6B.100d.txt\n",
            "Resolving aic.ai.wu.ac.at (aic.ai.wu.ac.at)... 137.208.107.25\n",
            "Connecting to aic.ai.wu.ac.at (aic.ai.wu.ac.at)|137.208.107.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347116733 (331M) [text/plain]\n",
            "Saving to: ‘glove.6B.100d.txt’\n",
            "\n",
            "glove.6B.100d.txt   100%[===================>] 331.04M  23.5MB/s    in 15s     \n",
            "\n",
            "2019-05-21 23:18:49 (21.7 MB/s) - ‘glove.6B.100d.txt’ saved [347116733/347116733]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTtLOK7pqK2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8214
        },
        "outputId": "456688b2-4f10-4679-f392-f729c3332bf0"
      },
      "source": [
        "!ludwig train --data_csv  cooking.stackexchange.csv --model_definition \"{input_features: [{name: text, type: text, embedding_size: 100, pretrained_embeddings: 'glove.6B.100d.txt', dropout: true}], output_features: [{name: labels, type: set}], training: {epochs: 50}}\""
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            " _         _        _      \n",
            "| |_  _ __| |_ __ _(_)__ _ \n",
            "| | || / _` \\ V  V / / _` |\n",
            "|_|\\_,_\\__,_|\\_/\\_/|_\\__, |\n",
            "                     |___/ \n",
            "ludwig v0.1.2 - Train\n",
            "\n",
            "Experiment name: experiment\n",
            "Model name: run\n",
            "Output path: results/experiment_run_9\n",
            "\n",
            "\n",
            "ludwig_version: '0.1.2'\n",
            "command: ('/usr/local/bin/ludwig train --data_csv cooking.stackexchange.csv '\n",
            " '--model_definition {input_features: [{name: text, type: text, '\n",
            " \"embedding_size: 100, pretrained_embeddings: 'glove.6B.100d.txt', dropout: \"\n",
            " 'True}], output_features: [{name: labels, type: set}], training: {epochs: '\n",
            " '50}}')\n",
            "random_seed: 42\n",
            "input_data: 'cooking.stackexchange.csv'\n",
            "model_definition: {   'combiner': {'type': 'concat'},\n",
            "    'input_features': [   {   'dropout': True,\n",
            "                              'embedding_size': 100,\n",
            "                              'encoder': 'parallel_cnn',\n",
            "                              'level': 'word',\n",
            "                              'name': 'text',\n",
            "                              'pretrained_embeddings': 'glove.6B.100d.txt',\n",
            "                              'tied_weights': None,\n",
            "                              'type': 'text'}],\n",
            "    'output_features': [   {   'dependencies': [],\n",
            "                               'loss': {'type': None, 'weight': 1},\n",
            "                               'name': 'labels',\n",
            "                               'reduce_dependencies': 'sum',\n",
            "                               'reduce_input': 'sum',\n",
            "                               'threshold': 0.5,\n",
            "                               'type': 'set'}],\n",
            "    'preprocessing': {   'bag': {   'fill_value': '',\n",
            "                                    'format': 'space',\n",
            "                                    'lowercase': False,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': 10000},\n",
            "                         'binary': {   'fill_value': 0,\n",
            "                                       'missing_value_strategy': 'fill_with_const'},\n",
            "                         'category': {   'fill_value': '<UNK>',\n",
            "                                         'lowercase': False,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 10000},\n",
            "                         'force_split': False,\n",
            "                         'image': {   'in_memory': True,\n",
            "                                      'missing_value_strategy': 'backfill',\n",
            "                                      'resize_method': 'crop_or_pad'},\n",
            "                         'numerical': {   'fill_value': 0,\n",
            "                                          'missing_value_strategy': 'fill_with_const'},\n",
            "                         'sequence': {   'fill_value': '',\n",
            "                                         'format': 'space',\n",
            "                                         'lowercase': False,\n",
            "                                         'missing_value_strategy': 'fill_with_const',\n",
            "                                         'most_common': 20000,\n",
            "                                         'padding': 'right',\n",
            "                                         'padding_symbol': '<PAD>',\n",
            "                                         'sequence_length_limit': 256,\n",
            "                                         'unknown_symbol': '<UNK>'},\n",
            "                         'set': {   'fill_value': '',\n",
            "                                    'format': 'space',\n",
            "                                    'lowercase': False,\n",
            "                                    'missing_value_strategy': 'fill_with_const',\n",
            "                                    'most_common': 10000},\n",
            "                         'split_probabilities': (0.7, 0.1, 0.2),\n",
            "                         'stratify': None,\n",
            "                         'text': {   'char_format': 'characters',\n",
            "                                     'char_most_common': 70,\n",
            "                                     'char_sequence_length_limit': 1024,\n",
            "                                     'fill_value': '',\n",
            "                                     'lowercase': True,\n",
            "                                     'missing_value_strategy': 'fill_with_const',\n",
            "                                     'padding': 'right',\n",
            "                                     'padding_symbol': '<PAD>',\n",
            "                                     'unknown_symbol': '<UNK>',\n",
            "                                     'word_format': 'space_punct',\n",
            "                                     'word_most_common': 20000,\n",
            "                                     'word_sequence_length_limit': 256},\n",
            "                         'timeseries': {   'fill_value': '',\n",
            "                                           'format': 'space',\n",
            "                                           'missing_value_strategy': 'fill_with_const',\n",
            "                                           'padding': 'right',\n",
            "                                           'padding_value': 0,\n",
            "                                           'timeseries_length_limit': 256}},\n",
            "    'training': {   'batch_size': 128,\n",
            "                    'bucketing_field': None,\n",
            "                    'decay': False,\n",
            "                    'decay_rate': 0.96,\n",
            "                    'decay_steps': 10000,\n",
            "                    'dropout_rate': 0.0,\n",
            "                    'early_stop': 5,\n",
            "                    'epochs': 50,\n",
            "                    'eval_batch_size': 0,\n",
            "                    'gradient_clipping': None,\n",
            "                    'increase_batch_size_on_plateau': 0,\n",
            "                    'increase_batch_size_on_plateau_max': 512,\n",
            "                    'increase_batch_size_on_plateau_patience': 5,\n",
            "                    'increase_batch_size_on_plateau_rate': 2,\n",
            "                    'learning_rate': 0.001,\n",
            "                    'learning_rate_warmup_epochs': 5,\n",
            "                    'optimizer': {   'beta1': 0.9,\n",
            "                                     'beta2': 0.999,\n",
            "                                     'epsilon': 1e-08,\n",
            "                                     'type': 'adam'},\n",
            "                    'reduce_learning_rate_on_plateau': 0,\n",
            "                    'reduce_learning_rate_on_plateau_patience': 5,\n",
            "                    'reduce_learning_rate_on_plateau_rate': 0.5,\n",
            "                    'regularization_lambda': 0,\n",
            "                    'regularizer': 'l2',\n",
            "                    'staircase': False,\n",
            "                    'validation_field': 'combined',\n",
            "                    'validation_measure': 'loss'}}\n",
            "\n",
            "\n",
            "Found hdf5 and json with the same filename of the csv, using them instead\n",
            "Using full hdf5 and json\n",
            "Loading data from: cooking.stackexchange.hdf5\n",
            "Loading metadata from: cooking.stackexchange.json\n",
            "Training set: 10875\n",
            "Validation set: 1453\n",
            "Test set: 3076\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "  Loading Glove format file glove.6B.100d.txt\n",
            "  400000 embeddings loaded\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/ludwig/models/modules/embedding_modules.py:139: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "From /usr/local/lib/python3.6/dist-packages/ludwig/models/modules/embedding_modules.py:139: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "\n",
            "╒══════════╕\n",
            "│ TRAINING │\n",
            "╘══════════╛\n",
            "\n",
            "2019-05-21 23:21:23.003746: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-05-21 23:21:23.003945: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3128ec0 executing computations on platform Host. Devices:\n",
            "2019-05-21 23:21:23.003973: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-05-21 23:21:23.123720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-05-21 23:21:23.124221: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x31292e0 executing computations on platform CUDA. Devices:\n",
            "2019-05-21 23:21:23.124250: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2019-05-21 23:21:23.124648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 14.73GiB freeMemory: 14.60GiB\n",
            "2019-05-21 23:21:23.124672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-05-21 23:21:23.476486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-05-21 23:21:23.476546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-05-21 23:21:23.476558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-05-21 23:21:23.476807: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-05-21 23:21:23.476850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14115 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "\n",
            "Epoch  1\n",
            "Training:   0% 0/85 [00:00<?, ?it/s]2019-05-21 23:21:24.040490: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "Training: 100% 85/85 [00:04<00:00, 18.35it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 206.90it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 71.03it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 141.33it/s]\n",
            "Took 5.3060s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 13.8810 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 14.3708 │    0.0000 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 13.9374 │    0.0000 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  2\n",
            "Training: 100% 85/85 [00:00<00:00, 87.77it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 331.42it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 333.02it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 327.97it/s]\n",
            "Took 1.3412s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 13.1933 │    0.0004 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 13.7736 │    0.0002 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 13.3340 │    0.0001 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  3\n",
            "Training: 100% 85/85 [00:00<00:00, 87.87it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 339.47it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 316.92it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 338.62it/s]\n",
            "Took 1.3337s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 12.2719 │    0.0127 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 13.0100 │    0.0107 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 12.5524 │    0.0109 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  4\n",
            "Training: 100% 85/85 [00:00<00:00, 87.13it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 341.74it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 309.63it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 334.48it/s]\n",
            "Took 1.3420s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 11.1651 │    0.0574 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 12.1203 │    0.0444 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 11.6554 │    0.0490 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  5\n",
            "Training: 100% 85/85 [00:01<00:00, 83.69it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 313.54it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 323.26it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 321.77it/s]\n",
            "Took 1.4081s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │ 10.0704 │    0.1115 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 11.2929 │    0.0862 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 10.8441 │    0.0983 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  6\n",
            "Training: 100% 85/85 [00:01<00:00, 84.86it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 314.50it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 323.06it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 330.06it/s]\n",
            "Took 1.3894s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │  9.0649 │    0.1661 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 10.6379 │    0.1333 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 10.1957 │    0.1438 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  7\n",
            "Training: 100% 85/85 [00:01<00:00, 84.10it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 317.10it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 330.55it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 331.49it/s]\n",
            "Took 1.3951s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │  8.1731 │    0.2199 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 10.1520 │    0.1673 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │  9.7129 │    0.1825 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  8\n",
            "Training: 100% 85/85 [00:01<00:00, 84.21it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 317.01it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 275.86it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 310.24it/s]\n",
            "Took 1.4064s\n",
            "╒══════════╤════════╤═══════════╕\n",
            "│ labels   │   loss │   jaccard │\n",
            "╞══════════╪════════╪═══════════╡\n",
            "│ train    │ 7.3834 │    0.2749 │\n",
            "├──────────┼────────┼───────────┤\n",
            "│ vali     │ 9.8016 │    0.2039 │\n",
            "├──────────┼────────┼───────────┤\n",
            "│ test     │ 9.3718 │    0.2124 │\n",
            "╘══════════╧════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch  9\n",
            "Training: 100% 85/85 [00:01<00:00, 84.08it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 325.12it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 340.72it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 326.08it/s]\n",
            "Took 1.3889s\n",
            "╒══════════╤════════╤═══════════╕\n",
            "│ labels   │   loss │   jaccard │\n",
            "╞══════════╪════════╪═══════════╡\n",
            "│ train    │ 6.7379 │    0.3249 │\n",
            "├──────────┼────────┼───────────┤\n",
            "│ vali     │ 9.5488 │    0.2307 │\n",
            "├──────────┼────────┼───────────┤\n",
            "│ test     │ 9.1262 │    0.2367 │\n",
            "╘══════════╧════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch 10\n",
            "Training: 100% 85/85 [00:01<00:00, 83.83it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 315.46it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 253.48it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 329.42it/s]\n",
            "Took 1.4111s\n",
            "╒══════════╤════════╤═══════════╕\n",
            "│ labels   │   loss │   jaccard │\n",
            "╞══════════╪════════╪═══════════╡\n",
            "│ train    │ 6.2370 │    0.3522 │\n",
            "├──────────┼────────┼───────────┤\n",
            "│ vali     │ 9.4414 │    0.2404 │\n",
            "├──────────┼────────┼───────────┤\n",
            "│ test     │ 9.0510 │    0.2410 │\n",
            "╘══════════╧════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch 11\n",
            "Training: 100% 85/85 [00:00<00:00, 87.47it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 339.73it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 350.81it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 297.80it/s]\n",
            "Took 1.3445s\n",
            "╒══════════╤════════╤═══════════╕\n",
            "│ labels   │   loss │   jaccard │\n",
            "╞══════════╪════════╪═══════════╡\n",
            "│ train    │ 5.5867 │    0.4135 │\n",
            "├──────────┼────────┼───────────┤\n",
            "│ vali     │ 9.2882 │    0.2621 │\n",
            "├──────────┼────────┼───────────┤\n",
            "│ test     │ 8.9091 │    0.2651 │\n",
            "╘══════════╧════════╧═══════════╛\n",
            "Validation loss on combined improved, model saved\n",
            "\n",
            "\n",
            "Epoch 12\n",
            "Training: 100% 85/85 [00:01<00:00, 84.71it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 309.30it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 314.44it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 312.30it/s]\n",
            "Took 1.4014s\n",
            "╒══════════╤════════╤═══════════╕\n",
            "│ labels   │   loss │   jaccard │\n",
            "╞══════════╪════════╪═══════════╡\n",
            "│ train    │ 5.2580 │    0.3985 │\n",
            "├──────────┼────────┼───────────┤\n",
            "│ vali     │ 9.7643 │    0.2403 │\n",
            "├──────────┼────────┼───────────┤\n",
            "│ test     │ 9.3068 │    0.2463 │\n",
            "╘══════════╧════════╧═══════════╛\n",
            "Last improvement of loss on combined happened 1 epoch ago\n",
            "\n",
            "\n",
            "Epoch 13\n",
            "Training: 100% 85/85 [00:01<00:00, 83.35it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 302.61it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 313.07it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 284.66it/s]\n",
            "Took 1.4317s\n",
            "╒══════════╤════════╤═══════════╕\n",
            "│ labels   │   loss │   jaccard │\n",
            "╞══════════╪════════╪═══════════╡\n",
            "│ train    │ 5.0151 │    0.4217 │\n",
            "├──────────┼────────┼───────────┤\n",
            "│ vali     │ 9.8269 │    0.2531 │\n",
            "├──────────┼────────┼───────────┤\n",
            "│ test     │ 9.4352 │    0.2603 │\n",
            "╘══════════╧════════╧═══════════╛\n",
            "Last improvement of loss on combined happened 2 epochs ago\n",
            "\n",
            "\n",
            "Epoch 14\n",
            "Training: 100% 85/85 [00:01<00:00, 82.48it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 311.74it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 310.66it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 296.12it/s]\n",
            "Took 1.4315s\n",
            "╒══════════╤════════╤═══════════╕\n",
            "│ labels   │   loss │   jaccard │\n",
            "╞══════════╪════════╪═══════════╡\n",
            "│ train    │ 4.3650 │    0.4941 │\n",
            "├──────────┼────────┼───────────┤\n",
            "│ vali     │ 9.5789 │    0.2725 │\n",
            "├──────────┼────────┼───────────┤\n",
            "│ test     │ 9.2092 │    0.2776 │\n",
            "╘══════════╧════════╧═══════════╛\n",
            "Last improvement of loss on combined happened 3 epochs ago\n",
            "\n",
            "\n",
            "Epoch 15\n",
            "Training: 100% 85/85 [00:01<00:00, 84.12it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 303.92it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 320.66it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 315.53it/s]\n",
            "Took 1.4116s\n",
            "╒══════════╤════════╤═══════════╕\n",
            "│ labels   │   loss │   jaccard │\n",
            "╞══════════╪════════╪═══════════╡\n",
            "│ train    │ 3.8599 │    0.5674 │\n",
            "├──────────┼────────┼───────────┤\n",
            "│ vali     │ 9.5111 │    0.2908 │\n",
            "├──────────┼────────┼───────────┤\n",
            "│ test     │ 9.1341 │    0.2950 │\n",
            "╘══════════╧════════╧═══════════╛\n",
            "Last improvement of loss on combined happened 4 epochs ago\n",
            "\n",
            "\n",
            "Epoch 16\n",
            "Training: 100% 85/85 [00:01<00:00, 83.55it/s]\n",
            "Evaluation train: 100% 85/85 [00:00<00:00, 307.34it/s]\n",
            "Evaluation vali : 100% 12/12 [00:00<00:00, 323.60it/s]\n",
            "Evaluation test : 100% 25/25 [00:00<00:00, 320.01it/s]\n",
            "Took 1.4139s\n",
            "╒══════════╤═════════╤═══════════╕\n",
            "│ labels   │    loss │   jaccard │\n",
            "╞══════════╪═════════╪═══════════╡\n",
            "│ train    │  3.8316 │    0.5151 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ vali     │ 10.6416 │    0.2554 │\n",
            "├──────────┼─────────┼───────────┤\n",
            "│ test     │ 10.1252 │    0.2561 │\n",
            "╘══════════╧═════════╧═══════════╛\n",
            "Last improvement of loss on combined happened 5 epochs ago\n",
            "\n",
            "EARLY STOPPING due to lack of validation improvement, it has been 5 epochs since last validation accuracy improvement\n",
            "\n",
            "Best validation model epoch:\n",
            "Best validation model loss on validation set combined: 9.288248207843148\n",
            "Best validation model loss on test set combined: 8.909082773602986\n",
            "\n",
            "Finished: experiment_run\n",
            "Saved to: results/experiment_run_9\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}