{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam Classification with ELMo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gwohlgen/colab/blob/master/Spam_Classification_with_ELMo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtpNE6TvrAvq",
        "colab_type": "text"
      },
      "source": [
        "# Spam Classification with ELMo \n",
        "### (based on this: http://hunterheidenreich.com/blog/elmo-word-vectors-in-keras/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W-Iajf7uzi4",
        "colab_type": "text"
      },
      "source": [
        "### Step 1: just load the spam datafile and set things up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp6UDOWjrc4A",
        "colab_type": "code",
        "outputId": "25639eff-19df-463b-85e1-afbb488f9fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "## get spam.csv\n",
        "!rm spam*\n",
        "!wget https://raw.githubusercontent.com/gwohlgen/misc/master/spam.csv\n",
        "!ls\n",
        "\n",
        "#!head spam.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-20 09:07:41--  https://raw.githubusercontent.com/gwohlgen/misc/master/spam.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 503663 (492K) [text/plain]\n",
            "Saving to: ‘spam.csv’\n",
            "\n",
            "\rspam.csv              0%[                    ]       0  --.-KB/s               \rspam.csv            100%[===================>] 491.86K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-05-20 09:07:42 (18.7 MB/s) - ‘spam.csv’ saved [503663/503663]\n",
            "\n",
            " data.csv      sample_data\n",
            " data_lm.pkl  'sentiment labelled sentences'\n",
            " __MACOSX     'sentiment labelled sentences.zip'\n",
            " models        spam.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeKSK0Z7q_5F",
        "colab_type": "code",
        "outputId": "763fbbd4-697b-41ef-9107-d33f47385abc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "url = \"https://tfhub.dev/google/elmo/2\"\n",
        "embed = hub.Module(url)\n",
        "\n",
        "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0520 09:07:48.522742 139829444708224 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0520 09:07:56.136458 139829444708224 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z2pBTXDuLVx",
        "colab_type": "text"
      },
      "source": [
        "### Step 2: Encode the labels (y) into a one-hot encoding\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bejHOAaxuEAC",
        "colab_type": "code",
        "outputId": "26db71cb-0b57-4d06-c839-acf31654e2b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "y = list(data['v1'])\n",
        "x = list(data['v2'])\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(y)\n",
        "\n",
        "def encode(le, labels):\n",
        "    enc = le.transform(labels)\n",
        "    return keras.utils.to_categorical(enc)\n",
        "\n",
        "def decode(le, one_hot):\n",
        "    dec = np.argmax(one_hot, axis=1)\n",
        "    return le.inverse_transform(dec)\n",
        "  \n",
        "## test label encoding\n",
        "test = encode(le, ['ham', 'spam', 'ham', 'ham'])\n",
        "untest = decode(le, test)\n",
        "\n",
        "print(test)\n",
        "print()\n",
        "print(untest)\n",
        "\n",
        "x_enc = x\n",
        "y_enc = encode(le, y)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n",
            "\n",
            "['ham' 'spam' 'ham' 'ham']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHovxmsZuJ5Q",
        "colab_type": "text"
      },
      "source": [
        "### Step 3: split in train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLwNQBN0rbsN",
        "colab_type": "code",
        "outputId": "d4173762-358c-4f1e-d195-28ffb84fceee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x_train = np.asarray(x_enc[:5000])\n",
        "y_train = np.asarray(y_enc[:5000])\n",
        "\n",
        "x_test = np.asarray(x_enc[5000:])\n",
        "y_test = np.asarray(y_enc[5000:])\n",
        "\n",
        "print(len(x_train), len(x_test))\n",
        "print('First test sentence:', len(x_train[0]), ' -- ', x_train[0], )"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000 572\n",
            "First test sentence: 111  --  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ_uNiEpv6rO",
        "colab_type": "text"
      },
      "source": [
        "### Step 4: Define the embedding function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OTvivjPrAIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "def ELMoEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"] # use default model of ELMo\n",
        "  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXEdrZ5A8hok",
        "colab_type": "text"
      },
      "source": [
        "### Excursus: See the embeddings\n",
        "based on: [https://tfhub.dev/google/elmo/2](https://tfhub.dev/google/elmo/2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX6lEVxo6v0g",
        "colab_type": "code",
        "outputId": "f8b39f3c-d4e1-4ee3-a0c6-999bf60c5534",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "## wohlg added -- see embeddings ..\n",
        "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
        "embeddings = elmo(\n",
        "    [\"the cat is on the mat\", \"dogs are in the fog\"],\n",
        "    signature=\"default\",\n",
        "    as_dict=True)[\"elmo\"]\n",
        "\n",
        "print(embeddings)\n",
        "\n",
        "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
        "embeddings = elmo(\n",
        "    [\"the cat is on the mat\", \"dogs are in the fog\"],\n",
        "    signature=\"default\",\n",
        "    as_dict=True)[\"word_emb\"]\n",
        "\n",
        "print(embeddings)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0520 09:33:37.492229 139829444708224 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"module_1_apply_default/aggregation/mul_3:0\", shape=(2, 6, 1024), dtype=float32)\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0520 09:33:38.961277 139829444708224 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"module_2_apply_default/bilm/Reshape_1:0\", shape=(2, 6, 512), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNHF-m_Cw4wT",
        "colab_type": "text"
      },
      "source": [
        "### Step 5: Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ7DwpAnwuBk",
        "colab_type": "code",
        "outputId": "d1f07b99-0851-43e7-bb3a-13ab5e8b9abe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "input_text = Input(shape=(1,), dtype=tf.string)\n",
        "embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text) # Elmo produces 1024-dim embeddings\n",
        "dense = Dense(256, activation='relu')(embedding)\n",
        "dense2= Dense(64, activation='relu')(dense) ## wohlg .. I added this for testing\n",
        "pred = Dense(2, activation='softmax')(dense2) \n",
        "model = Model(inputs=[input_text], outputs=pred)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.layers)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0520 09:34:28.329293 139829444708224 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[<keras.engine.input_layer.InputLayer object at 0x7f2c23a65320>, <keras.layers.core.Lambda object at 0x7f2c23a651d0>, <keras.layers.core.Dense object at 0x7f2c77cc8dd8>, <keras.layers.core.Dense object at 0x7f2c22f54f28>, <keras.layers.core.Dense object at 0x7f2c23a65048>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m760CZ5mw_BB",
        "colab_type": "text"
      },
      "source": [
        "### Step 6: train the model and save it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdUGZMFGw-Hv",
        "colab_type": "code",
        "outputId": "57c747bd-74d3-4e45-ee5f-dcf616ac8280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())  \n",
        "    session.run(tf.tables_initializer())\n",
        "    history = model.fit(x_train, y_train, epochs=2, batch_size=32)\n",
        "    model.save_weights('./elmo-model.h5')\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0520 09:34:40.156120 139829444708224 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "5000/5000 [==============================] - 96s 19ms/step - loss: 0.0972 - acc: 0.9676\n",
            "Epoch 2/2\n",
            "5000/5000 [==============================] - 80s 16ms/step - loss: 0.0564 - acc: 0.9832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86pHQJYIx4Px",
        "colab_type": "text"
      },
      "source": [
        "### Step 7: Load the mode, and do predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daZ0_dxyxzuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    session.run(tf.tables_initializer())\n",
        "    model.load_weights('./elmo-model.h5')  \n",
        "    predicts = model.predict(x_test, batch_size=32)\n",
        "\n",
        "y_test = decode(le, y_test)\n",
        "y_preds = decode(le, predicts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kbeJKotv5WL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLtGDumTsTEc",
        "colab_type": "code",
        "outputId": "1be82a8c-ea91-40ae-c617-e3ae77d239c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(metrics.confusion_matrix(y_test, y_preds))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_preds))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[496   2]\n",
            " [  5  69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      1.00      0.99       498\n",
            "        spam       0.97      0.93      0.95        74\n",
            "\n",
            "   micro avg       0.99      0.99      0.99       572\n",
            "   macro avg       0.98      0.96      0.97       572\n",
            "weighted avg       0.99      0.99      0.99       572\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}